[deepnlp_default]
# where downloaded corpora are stored and accessed
corpus_dir = ${default:root_dir}/corpus

# the document parser used for vectorization
vectorizer_doc_parser = doc_parser

# the embedding to use for any models using word vectors
embedding = glove_50_embedding

# freeze the embedding to train faster
glove_trainable = False
word2vec_trainable = False
fasttext_trainable = False

# serialize (pickle) the decoded output to do the work up front
transformer_encode_transformed = False
glove_encode_transformed = False
word2vec_encode_transformed = False
fasttext_encode_transformed = False

# from_pretrain extra arguments; speeds things up, but set to True for the
# first pretrained download
transformer_local_files_only = False

# max wordpiece length for transformer tokenization; default to model's input
word_piece_token_length = 0

# word_piece_document_factory default embedding name
word_piece_embedding = transformer_sent_fixed

# RNN layers, which must be overridden if used
num_labels = -1
labels = None
