## Lingustic features
#
# creates one hot vectors for each enumeration of the spaCy feature parsed in
# `doc_parser`.
[enum_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.EnumContainerFeatureVectorizer
feature_id = enum
# serialize (pickle) the decoded output to do the work up front
encode_transformed = False
# the feature ids to use at train/test time, which currently are all those
# defined in `zensols.deepnlp.vectorize.SpacyFeatureVectorizer`, and include
# 'ent', 'tag', and 'dep'
#
# train time tweakable
#decoded_feature_ids = set: ent, tag, dep

# creates counts of for each enumeration of the SpaCy feature parsed in
# `doc_parser`.
[count_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.CountEnumContainerFeatureVectorizer
feature_id = count
# serialize (pickle) the decoded output to do the work up front
encode_transformed = False
# the feature ids to use at train/test time, which currently are all those
# defined in `zensols.deepnlp.vectorize.SpacyFeatureVectorizer`, and include
# 'ent', 'tag', and 'dep'
#
# train time tweakable
#decoded_feature_ids = eval: set('ent tag dep'.split())

# language statistic (no of tokens, etc)
[stats_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.StatisticsFeatureDocumentVectorizer
feature_id = stats
# serialize (pickle) the decoded output to do the work up front
encode_transformed = False

# head tree dependency features
[depth_token_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.DepthFeatureDocumentVectorizer
feature_id = dep
# serialize (pickle) the decoded output to do the work up front
encode_transformed = False


## Vectorizer and managers

# a language specific vectorizer manager that uses the FeatureDocumentParser
# defined in `doc_parser` to create word embeddings using the vectorizer
# defined in `glove_50_feature_vectorizer` and natural language features
[language_vectorizer_manager]
class_name = zensols.deepnlp.vectorize.FeatureDocumentVectorizerManager
torch_config = instance: gpu_torch_config
doc_parser = instance: doc_parser
# do not truncate tokens
token_length = -1
configured_vectorizers = list:
  count_feature_vectorizer,
  enum_feature_vectorizer,
  stats_feature_vectorizer,
  depth_token_feature_vectorizer,
  glove_50_feature_vectorizer,
  glove_300_feature_vectorizer,
  word2vec_300_feature_vectorizer,
  fasttext_news_300_feature_vectorizer,
  fasttext_crawl_300_feature_vectorizer,
  transformer_trainable_feature_vectorizer,
  transformer_fixed_feature_vectorizer,
  transformer_sent_trainable_feature_vectorizer,
  transformer_sent_fixed_feature_vectorizer


# maintains a collection of all vectorizers for the framework
[vectorizer_manager_set]
class_name = zensols.deeplearn.vectorize.FeatureVectorizerManagerSet
names = list: language_vectorizer_manager
