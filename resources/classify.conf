## Classification labels

## Import mappings
[import]
sections = list: imp_classify_batch

[imp_classify_batch]
type = import
config_file = resource(zensols.deepnlp): resources/classify-batch.yml


## Vectorization
#
# vectorize the labels from text to PyTorch tensors
[classify_label_vectorizer]
class_name = zensols.deeplearn.vectorize.NominalEncodedEncodableFeatureVectorizer
#categories = y, n
feature_id = lblabel

# the vectorizer for labels is not language specific and lives in the
# zensols.deeplearn.vectorize package, so it needs it's own instance
[classify_label_vectorizer_manager]
class_name = zensols.deeplearn.vectorize.FeatureVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = list: classify_label_vectorizer

# maintains a collection of all vectorizers for the framework
[vectorizer_manager_set]
names = list: language_vectorizer_manager, classify_label_vectorizer_manager


## Batch
#
[batch_dir_stash]
# feature grouping: when at least one in a group is needed, all of the features
# in that group are loaded
groups = eval: (
       # there will be N (batch_stash:batch_size) batch labels in one file in a
       # directory of just label files
       set('label'.split()),
       # because we might want to switch between embeddings, separate them
       set('glove_50_embedding'.split()),
       set('glove_300_embedding'.split()),
       set('word2vec_300_embedding'.split()),
       set('fasttext_news_300_embedding'.split()),
       set('fasttext_crawl_300_embedding'.split()),
       set('enums stats counts dependencies'.split()),
       set('transformer_trainable_embedding'.split()),
       set('transformer_fixed_embedding'.split()),
       set('transformer_sent_trainable_embedding'.split()),
       set('transformer_sent_fixed_embedding'.split()),
       set('transformer_enum_expander transformer_dep_expander'.split()))

[batch_stash]
# the class that contains the feature data, one for each data instance
data_point_type = eval({'import': ['zensols.deepnlp.classify']}): zensols.deepnlp.classify.LabeledFeatureDocumentDataPoint
# map feature attributes (sections) to feature IDs to connect features to vectorizers
batch_feature_mappings = dataclass(zensols.deeplearn.batch.ConfigBatchFeatureMapping): classify_batch_mappings
# this stash is used to generate instances of what will be used to create batches
split_stash_container = instance: feature_stash


## Facade
#
# declare the ModelFacade to use for the application
[facade]
class_name = zensols.deepnlp.classify.ClassifyModelFacade


## Model
#
# tell the model automation API which model to use
[executor]
net_settings = instance: classify_net_settings

[model_settings]
prediction_mapper_name = classify_feature_prediction_mapper

# the network configuration, which contains constant information (as opposed to
# dynamic configuration such as held back `stash:decoded_attributes`)
[classify_net_settings]
class_name = zensols.deepnlp.classify.ClassifyNetworkSettings
# gpu layer configuration
torch_config = instance: ${deeplearn_default:layer_torch_config}
#
# embedding layer used as the input layer (i.e. glove_50_embedding)
#embedding_layer = instance: ${deepnlp_default:embedding}_layer
#
# the (potentially) deep linear network
linear_settings = instance: linear_settings
#
# the optional recurrent neural network after the embeddings
recurrent_settings = None
#
# the optional convolution
convolution_settings = None
#
# the batch stash is used to create the batch metadata
batch_stash = instance: batch_stash
#
# sets the dropout for the network
dropout = None


## Prediction
#
# create data points from the client
[classify_feature_prediction_mapper]
class_name = zensols.deepnlp.classify.ClassificationPredictionMapper
vec_manager = instance: language_vectorizer_manager
label_feature_id = classify_label_vectorizer_manager.lblabel
