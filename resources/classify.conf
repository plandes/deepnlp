## Classification labels

# vectorize the labels from text to PyTorch tensors
[classify_label_vectorizer]
class_name = zensols.deeplearn.vectorize.NominalEncodedEncodableFeatureVectorizer
#--config note: uncomment, but be careful not to inclue a ``list:``
#categories = y, n
feature_id = lblabel

# the vectorizer for labels is not language specific and lives in the
# zensols.deeplearn.vectorize package, so it needs it's own instance
[classify_label_vectorizer_manager]
class_name = zensols.deeplearn.vectorize.FeatureVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = list: classify_label_vectorizer


## Prediction mapper

# create data points from the client
[classify_feature_prediction_mapper]
class_name = zensols.deepnlp.classify.ClassificationPredictionMapper
vec_manager = instance: language_feature_manager
label_feature_id = classify_label_vectorizer_manager.lblabel


## Batch
[batch_dir_stash]
# feature grouping: when at least one in a group is needed, all of the features
# in that group are loaded
groups = eval: (
       # there will be N (batch_stash:batch_size) batch labels in one file in a
       # directory of just label files
       set('label'.split()),
       # because we might want to switch between embeddings, separate them
       set('glove_50_embedding'.split()),
       set('glove_300_embedding'.split()),
       set('word2vec_300_embedding'.split()),
       set('fasttext_news_300_embedding'.split()),
       set('fasttext_crawl_300_embedding'.split()),
       set('enums stats counts dependencies'.split()),
       set('transformer_trainable_embedding'.split()),
       set('transformer_fixed_embedding'.split()))

[batch_stash]
# the class that contains the feature data, one for each data instance
data_point_type = eval({'import': ['zensols.deepnlp.classify']}): zensols.deepnlp.classify.LabeledFeatureDocumentDataPoint
# the class taht contains the batch data, which will have N instances of
# `data_point_type` where N is the `batch_size`
#batch_type = eval({'import': ['zensols.deepnlp.classify']}): zensols.deepnlp.classify.LabeledBatch
batch_type = eval({'import': ['zensols.deeplearn.batch']}): zensols.deeplearn.batch.DefaultBatch
# map feature attributes (sections) to feature IDs to connect features to vectorizers
batch_feature_mappings = dataclass(zensols.deeplearn.batch.ConfigBatchFeatureMapping): classify_batch_mappings

# declare the ModelFacade to use for the application
[facade]
class_name = zensols.deepnlp.classify.ClassifyModelFacade



## model

# the network configuration, which contains constant information (as opposed to
# dynamic configuration such as held back `stash:decoded_attributes`)
[classify_net_settings]
class_name = zensols.deepnlp.classify.ClassifyNetworkSettings
# embedding layer used as the input layer
#embedding_layer = instance: ${deepnlp_default:embedding}_layer
#
# the recurrent neural network after the embeddings
recurrent_settings = None
#
# the (potentially) deep linear network
linear_settings = instance: linear_settings
#
# the batch stash is used to create the batch metadata
batch_stash = instance: batch_stash
#
# sets the dropout for the network
dropout = None
