## word2vec
[word2vec_300_embedding]
class_name = zensols.deepnlp.embed.Word2VecModel
path = path: ${deepnlp_default:model_dir}/GoogleNews-vectors-negative300.bin
dimension = 300

[word2vec_300_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.WordVectorEmbeddingFeatureVectorizer
feature_id = w2v300
embed_model = instance: word2vec_300_embedding
# do not serialize (pickle) the decoded output to do the work up front
encode_transformed = False
# decode the embedding during the decode phase, which speeds things up since we
# GPU cache batches (model_settings:batch_iteration = gpu)
decode_embedding = True

[word2vec_300_embedding_layer]
class_name = zensols.deepnlp.layer.WordVectorEmbeddingLayer
embed_model = instance: word2vec_300_embedding
feature_vectorizer = instance: language_feature_manager
