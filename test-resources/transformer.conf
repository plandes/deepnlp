# config
[filter_token_mapper]
class_name = zensols.nlp.FilterTokenMapper
remove_space = True

[token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = eval: 'filter_token_mapper'.split()

[langres]
class_name = zensols.nlp.LanguageResource
token_normalizer = instance: token_normalizer

[langres_default]
class_name = zensols.nlp.LanguageResource

[torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = False
data_type = eval({'import': ['torch']}): torch.float64


# transformer
[transformer_resource]
class_name = zensols.deepnlp.transformer.TransformerResource
torch_config = instance: torch_config
model_id = bert-base-cased
cased = True
# subproc CPU to CPU copy bug: https://github.com/huggingface/transformers/issues/8649
cache = True
# whether or not the embeddings are trainable
trainable = False

[transformer_tokenizer]
class_name = zensols.deepnlp.transformer.TransformerDocumentTokenizer
resource = instance: transformer_resource
word_piece_token_length = 0

[transformer_embedding]
class_name = zensols.deepnlp.transformer.TransformerEmbedding
tokenizer = instance: transformer_tokenizer
output = last_hidden_state

[transformer_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.TransformerEmbeddingFeatureVectorizer
feature_id = transformer
embed_model = instance: transformer_embedding
encode_transformed = False

[transformer_embedding_layer]
class_name = zensols.deepnlp.vectorize.TransformerEmbeddingLayer
embed_model = instance: transformer_embedding
feature_vectorizer = instance: language_feature_manager


# document parsers
[doc_parser]
class_name = zensols.deepnlp.FeatureDocumentParser
langres = instance: langres

# managers
[feature_vectorizer_manager]
class_name = zensols.deepnlp.vectorize.FeatureDocumentVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = list: transformer_feature_vectorizer
doc_parser = instance: doc_parser
token_length = 0
