[filter_token_mapper]
class_name = zensols.nlp.FilterTokenMapper
remove_space = True

[token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = eval: 'filter_token_mapper'.split()

[langres]
class_name = zensols.nlp.LanguageResource
token_normalizer = instance: token_normalizer

[torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = False
data_type = eval({'import': ['torch']}): torch.float64


[doc_parser]
class_name = zensols.deepnlp.FeatureDocumentParser
langres = instance: langres
token_feature_ids = eval: set('ent dep norm'.split())

[ent_dep_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.EnumContainerFeatureVectorizer
feature_id = enum

[ent_dep_vectorizer_manager]
class_name = zensols.deepnlp.vectorize.FeatureDocumentVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = eval: 'ent_dep_feature_vectorizer'.split()
token_feature_ids = ${doc_parser:token_feature_ids}
doc_parser = instance: doc_parser
token_length = 30


[ent_feature_vectorizer]
class_name = zensols.deepnlp.vectorize.EnumContainerFeatureVectorizer
feature_id = enum
decoded_feature_ids = eval: set(['ent'])

[ent_vectorizer_manager]
class_name = zensols.deepnlp.vectorize.FeatureDocumentVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = eval: 'ent_feature_vectorizer'.split()
token_feature_ids = ${doc_parser:token_feature_ids}
doc_parser = instance: doc_parser
token_length = 30

[ent_vectorizer_manager_nolen]
class_name = zensols.deepnlp.vectorize.FeatureDocumentVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = eval: 'ent_feature_vectorizer'.split()
token_feature_ids = ${doc_parser:token_feature_ids}
doc_parser = instance: doc_parser
token_length = -1
