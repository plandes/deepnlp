{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning framework example: Clickbate dataset\n",
    "\n",
    "**Important**: Please see the [MNIST notebook example](https://github.com/plandes/deeplearn/blob/master/notebook/mnist.ipynb) in the [zensols.deeplearn](https://github.com/plandes/deeplearn) API first, as it contains more explaination of how the framework is used.\n",
    "\n",
    "See the [saved notebook](https://htmlpreview.github.io/?https://github.com/plandes/deepnlp/blob/master/example/clickbate/notebook/clickbate.html) to see the output of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# environemnt configuration and set up: add this (deepnlp) library to the Python path and framework entry point\n",
    "from mngfac import JupyterManagerFactory\n",
    "fac = JupyterManagerFactory()\n",
    "mng = fac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print information about \n",
    "\n",
    "Use the factory to create the model executor.  The `write` method gives statistics on the data set that is configured on the executor.  Note that the first time this runs, the framework automatically downloads the corpus, vectorizers and creates batches for quick experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the configuration from glove.conf using the same command line process to load the config and models\n",
    "facade = mng.create_facade('glove_50')\n",
    "mng.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "Clear language attributes for a baseline to get a feel for where they need to be before changing features.  Start with Glove 50 dimensional word embeddings (set in the last cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove language features for a baseline, then add back later\n",
    "facade.language_attributes = set()\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune parameters\n",
    "\n",
    "Try a lower learning rate for more epochs to see if it improves performance.  Over estimating the epoch count is hedged by the model only saving on validation loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "default_lr = facade.learning_rate\n",
    "default_epochs = facade.epochs\n",
    "facade.learning_rate = facade.learning_rate - (facade.learning_rate/10)\n",
    "facade.epochs = 50\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add language features\n",
    "\n",
    "Since adjusting the learning rate didn't show a significant positive change, restore the previous learning rate.  Instead, we'll try to add spaCy generated language features by appending them to the embedding layer.  The enumerations are one-hot encoded vectors of POS tags, NER entities and dependenccy parent/child relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "facade.learning_rate = default_lr\n",
    "facade.epochs = default_epochs\n",
    "facade.language_attributes = {'enums'}\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More linguistic features\n",
    "\n",
    "Add the syntactic dependency head parent/child relationship as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "facade.language_attributes = {'enums', 'dependencies'}\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try fasttext news embeddings\n",
    "\n",
    "Note that we can experiment by setting the embedings directly in the old facade.  However, recreating the facade is usually better to capture the proper set up by starting fresh.  All configuration is reset and reloaded so the language features are added back automatically.  Another advantage to using the `create_facade` method is that all random state is reset for consistency of each new test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fasttext embeddings converge faster so lower the epoch count\n",
    "facade.epochs = 25\n",
    "facade = mng.create_facade('fasttext_news_300')\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results\n",
    "\n",
    "Generate a dataframe with the performance metrics of the previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zensols.deeplearn.result import ModelResultManager, ModelResultReporter\n",
    "rm: ModelResultManager = facade.result_manager\n",
    "reporter = ModelResultReporter(rm, include_validation=False)\n",
    "reporter.dataframe.drop(columns=['file'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
