{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning framework example: Movie Review Dataset\n",
    "\n",
    "This notebook demonstrates how to use the deeplearning API to train and test the model on the [Stanford movie review corpus](https://nlp.stanford.edu/sentiment/) corpus.  This dataset contains hand written digits and their labels.  See the [saved version](https://github.com/plandes/deepnlp/blob/master/example/movie/notebook/movie.html) for output.\n",
    "\n",
    "Before you run this notebook, you must ensure the corpus is installed.  Please see this example's [online documentation](https://plandes.github.io/deepnlp/doc/movie-example.html) file for more information.  Jupyter should be started from the `example/movie` directory.\n",
    "\n",
    "**Important**: Please see the Iris notebook example in the `zensols.deeplearn` API first, as it contains more explaination of how the framework is used.  The purpose of this notebook is to run the MNIST dataset and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environemnt configuration and set up: add this (deepnlp) library to the Python path and framework entry point\n",
    "from harness import NotebookHarness\n",
    "harness = NotebookHarness()\n",
    "mng = harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print information about \n",
    "\n",
    "Use the factory to create the model executor.  The `write` method gives statistics on the data set that is configured on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "facade = mng.create_facade('glove50')\n",
    "from zensols.config import Writable\n",
    "# set indention level for human readable (pretty print like) output\n",
    "Writable.WRITABLE_INDENT_SPACE = 2\n",
    "facade.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model\n",
    "\n",
    "Train and test the model with the default (low) number of epochs to make sure everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.epochs = 2\n",
    "mng.run(display_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters\n",
    "\n",
    "Set model parameters to get a feel for where they need to be before changing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.epochs = 75\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the embedding updates the model, but currently results show initial loaded embeddings (glove50)\n",
    "facade.embedding = 'word2vec_300_embedding'\n",
    "mng.run()\n",
    "# persist the plot and results to the file system (commented out to keep results only in notepad)\n",
    "#facade.persist_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# when comparing several models with the same embeddings with different language\n",
    "# features (later cells), recreate to get a consistent random seed and clean state\n",
    "facade = mng.create_facade('transformer-fixed')\n",
    "facade.language_attributes = set()\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-fixed')\n",
    "facade.epochs = 35\n",
    "facade.language_attributes = {'enum_expander'}\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-fixed')\n",
    "facade.language_attributes = {'enum_expander', 'dep_expander'}\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-fixed')\n",
    "facade.language_attributes = {'dep_expander'}\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-trainable')\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-trainable')\n",
    "facade.model_settings.optimizer_params = {'weight_decay': 0.005}\n",
    "facade.model_settings.scheduler_params = {'patience': 3}\n",
    "facade.epochs = 25\n",
    "mng.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
