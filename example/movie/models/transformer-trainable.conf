[model_defaults]
embedding = transformer_trainable_embedding
#embedding = transformer_fixed_embedding
lang_features = 
#lang_features = dep_expander,

[net_settings]
#recurrent_settings = instance: recurrent_settings
recurrent_settings = None
dropout = 0.1

[transformer_trainable_embedding]
class_name = zensols.deepnlp.transformer.TransformerEmbedding
tokenizer = instance: transformer_trainable_tokenizer
output = pooler_output

[linear_settings]
class_name = zensols.deeplearn.layer.DeepLinearNetworkSettings
# decoder
middle_features = eval: []

[model_settings]
epochs = 35
learning_rate = eval: 2e-6
optimizer_class_name = zensols.deepnlp.transformer.TransformerAdamW
optimizer_params = dict: {'weight_decay': 0.01}
scheduler_params = dict: {'patience': 5}
