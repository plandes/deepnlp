## defaults
[default]
root_dir = .
data_dir = ${root_dir}

[deeplearn_default]
batch_dir = ${default:data_dir}/batch
temporary_dir = ${default:data_dir}/model
results_dir = ${default:root_dir}/results
model_name = none

[deepnlp_default]
model_dir = ${default:root_dir}/model/nlp


## document
# creates features from documents by invoking by using SpaCy to parse the text
[doc_parser]
# dep head tree features
token_feature_ids = set: ent_, dep_, norm, ent, dep, tag, tag_, children, i, dep_, is_punctuation, idx, i_sent


## vectorizer
# creates counts of for each enumeration of the SpaCy feature parsed in
# `doc_parser`.
[count_feature_vectorizer]
decoded_feature_ids = set: ent, tag, dep

# creates one hot vectors for each enumeration of the SpaCy feature parsed in
# `doc_parser`.
[enum_feature_vectorizer]
decoded_feature_ids = set: ent, tag, dep

[transformer_fixed_embedding]
# class_name = zensols.deepnlp.transformer.TransformerEmbedding
# tokenizer = instance: transformer_tokenizer
output = last_hidden_state

# mapper
[transformer_fixed_expander_vectorizer]
delegate_feature_ids = list: dep, enum

[transformer_bigbird_embedding]
output = last_hidden_state


## manager
#
# a language specific vectorizer manager that uses the FeatureDocumentParser
# defined in `doc_parser` to create word embeddings using the vectorizer
# defined in `glove_50_feature_vectorizer` and natural language features
[language_vectorizer_manager]
token_feature_ids = ${doc_parser:token_feature_ids}
configured_vectorizers = list:
  count_feature_vectorizer,
  enum_feature_vectorizer,
  stats_feature_vectorizer,
  depth_token_feature_vectorizer,
  glove_50_feature_vectorizer,
  glove_300_feature_vectorizer,
  transformer_trainable_feature_vectorizer,
  transformer_fixed_feature_vectorizer,
  transformer_bigbird_feature_vectorizer
