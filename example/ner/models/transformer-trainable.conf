[embedding_constants]
name = transformer_trainable_embedding

[language_defaults]
embedding = ${embedding_constants:name}

[sent_batch_stash]
# train time tweakable
decoded_attributes = eval: set([
  # label (named entity)
  'ents',
  # mask on the named entity labels used by the LSTM+CRF
  'mask',
  # expanded tags for the transformer
#  'tags_expander', 'syns_expander',
#  'ents_expander',
  'ents_trans',
  # the embedding to use (one of many defined in `embeddings.conf`)
  '${language_defaults:embedding}'])

[trans_decoder_settings]
class_name = zensols.deeplearn.layer.DeepLinearNetworkSettings
# number deep linear layers configured after the LSTM
middle_features = eval: []
# number of output features
out_features = ${label_constants:n_labels}
# the number of input features to the deep linear layer; set to null since
# calculated in the model
in_features = None
# whether to treat each middle layer as a scalar multiplier of the previous or
# to interpret them as a constant number of parameters
proportions = True
# number of times to repeat the middle layers
repeats = 1
# drop out used for the middle layers (set by root level settings)
dropout = 0.1
# activation
activation = None
# 1d batch normalize
batch_norm_d = None
batch_norm_features = None

[trans_net_settings]
class_name = zensols.deepnlp.transformer.TransformerSequenceLayerNetworkSettings
# embedding layer used as the input layer
#embedding_layer = NONE
embedding_layer = instance: ${embedding_constants:name}_layer
#
decoder_settings = instance: trans_decoder_settings
# metadata factory helps configure the network (see that configuration)
batch_metadata_factory = instance: sent_batch_metadata_factory

[executor]
net_settings = instance: trans_net_settings

[model_settings]
# number of epochs to train the model
epochs = 1
