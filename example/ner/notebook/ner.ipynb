{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning framework example: Named Entity Recognition\n",
    "\n",
    "This notebook demonstrates how to use the deeplearning API to train and test the model on the [CoNNL 2003 dataset](https://www.clips.uantwerpen.be/conll2003/ner/).  The task is to identify named entities (i.e. people, organizations etc).\n",
    "\n",
    "**Important**: Please see the Movie Review notebook example in the `zensols.movie` API first, as it contains more explaination of how the framework is used.  The purpose of this notebook is to run the MNIST dataset and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up notebook environment\n",
    "import sys\n",
    "from pathlib import Path\n",
    "app_root_dir = Path('..')\n",
    "# add the example to the Python library path\n",
    "sys.path.append(str(app_root_dir / 'src'))\n",
    "# add the deepnlp path\n",
    "sys.path.append('../../../src/python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and create the app specific facade\n",
    "\n",
    "Now that the interpreter environment is set up, we can import local packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zensols.deeplearn import TorchConfig\n",
    "from zensols.deeplearn.cli import JupyterManager\n",
    "from ner import CliFactory\n",
    "\n",
    "# reset random state for consistency of each new test that uses this function\n",
    "TorchConfig.init()\n",
    "\n",
    "mng = JupyterManager(\n",
    "    allocation_tracking=True,\n",
    "    cli_class=CliFactory,\n",
    "    factory_args={'root_dir': app_root_dir},\n",
    "    cli_args_fn=lambda model: ['-c', str(app_root_dir / 'models' / f'{model}.conf')])\n",
    "\n",
    "reset_epochs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print information about \n",
    "\n",
    "Use the factory to create the model executor.  The `write` method gives statistics on the data set that is configured on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from zensols.config import Writable\n",
    "# set indention level for human readable (pretty print) output\n",
    "Writable.WRITABLE_INDENT_SPACE = 2\n",
    "facade = mng.create_facade('glove50')\n",
    "facade.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model\n",
    "\n",
    "Train and test the model with the default (low) number of epochs to make sure everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.epochs = 2\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters\n",
    "\n",
    "Set model parameters to get a feel for where they need to be before changing features.  Start with Glove 50 dimensional word embeddings with a learning rate of 0.01 and 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.learning_rate = 0.01\n",
    "if reset_epochs:\n",
    "    facade.epochs = 20\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove 300 embeddings\n",
    "\n",
    "Next we use the same learning rate, but switch to the 300 dimension version of the embeddings.  The number of epochs is reduced because I have run the test before I know at what epoch the validation loss converges.  Since the model is saved only when the validation loss decreases, we early stop at 8 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_epochs:\n",
    "    facade.epochs = 8\n",
    "facade.embedding = 'glove_300_embedding'\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec Embeddings\n",
    "\n",
    "Now we switch to the Google 300D word2vec pretrained vectors using 12 epochs, even though it has converged at 9 epochs previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_epochs:\n",
    "    facade.epochs = 12\n",
    "facade.embedding = 'word2vec_300_embedding'\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Embeddings\n",
    "\n",
    "Now we test with Bert context aware frozen (not trainable) embeddings using 10 epochs.  We must empty the `net_settings` attributes, which are the lingustic features, since Bert tokenizes using the word piece algorithm and the tensor shapes will not align.  We'll address this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-fixed')\n",
    "facade.epochs = 1\n",
    "if reset_epochs:\n",
    "    facade.epochs = 10\n",
    "facade.net_settings.add_attributes = ()\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.net_settings.add_attributes = ('syns_expander', 'tags_expander')\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    mng.show_leaks()\n",
    "    mng.cleanup()\n",
    "else:\n",
    "    facade = mng.create_facade('transformer-trainable')\n",
    "    facade.model_settings.batch_limit = 1\n",
    "    facade.epochs = 1\n",
    "    #logging.getLogger('zensols.deepnlp.vectorize.layer').setLevel(logging.DEBUG)\n",
    "    mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from zensols.persist import Deallocatable\n",
    "#Deallocatable._print_undeallocated(only_counts=False, include_stack=True)\n",
    "#mng.deallocate()\n",
    "#mng.cleanup()\n",
    "#mng.show_leaks()\n",
    "#a = next(iter(Deallocatable.ALLOCATIONS.values()))[0]\n",
    "#print(type(a), a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
