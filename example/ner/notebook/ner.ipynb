{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning framework example: Named Entity Recognition\n",
    "\n",
    "This notebook demonstrates how to use the deeplearning API to train and test the model on the [CoNNL 2003 dataset](https://www.clips.uantwerpen.be/conll2003/ner/).  The task is to identify named entities (i.e. people, organizations etc).\n",
    "\n",
    "**Important**: Please see the Movie Review notebook example in the `zensols.movie` API first, as it contains more explaination of how the framework is used.  The purpose of this notebook is to run the MNIST dataset and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up notebook environment\n",
    "import sys\n",
    "from pathlib import Path\n",
    "app_root_dir = Path('..')\n",
    "# add the example to the Python library path\n",
    "sys.path.append(str(app_root_dir / 'src'))\n",
    "# add the deepnlp path\n",
    "sys.path.append('../../../src/python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and create the app specific facade\n",
    "\n",
    "Now that the interpreter environment is set up, we can import local packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zensols.deeplearn import TorchConfig\n",
    "from zensols.deeplearn.cli import JupyterManager\n",
    "from ner import CliFactory\n",
    "\n",
    "# reset random state for consistency of each new test that uses this function\n",
    "TorchConfig.init()\n",
    "\n",
    "mng = JupyterManager(\n",
    "    allocation_tracking=True,\n",
    "    cli_class=CliFactory,\n",
    "    factory_args={'root_dir': app_root_dir},\n",
    "    cli_args_fn=lambda model: ['-c', str(app_root_dir / 'models' / f'{model}.conf')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print information about \n",
    "\n",
    "Use the factory to create the model executor.  The `write` method gives statistics on the data set that is configured on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-17 14:42:25,173 [zensols.deeplearn.model.facade] creating new executor\n",
      "2021-06-17 14:42:26,060 [zensols.deepnlp.embed.wordtext] reading binary vector file: ../corpus/glove/bin/6B.50/vec\n",
      "2021-06-17 14:42:26,368 [zensols.deepnlp.embed.wordtext] loaded 400000 vectors in 0s\n",
      "2021-06-17 14:42:26,650 [zensols.deepnlp.embed.wordtext] prepared vectors in 0s\n",
      "2021-06-17 14:42:26,651 [zensols.deepnlp.embed.domain] created tensor vectory matrix on use cuda: True, device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executor:\n",
      "  model: NER: glove_50 \n",
      "  feature splits:\n",
      "    split stash splits:\n",
      "        test: 3453 (16.6%)\n",
      "        train: 14041 (67.7%)\n",
      "        dev: 3250 (15.7%)\n",
      "        total: 20744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-17 14:42:29,930 [zensols.deeplearn.model.executor.status] created model on cpu with use cuda: True, device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    total this instance: 20744\n",
      "    keys consistent: True\n",
      "    delegate:\n",
      "      key splits:\n",
      "        test: 3453 (16.6%)\n",
      "        train: 14041 (67.7%)\n",
      "        dev: 3250 (15.7%)\n",
      "      total: 20744\n",
      "  batch splits:\n",
      "    split stash splits:\n",
      "        test: 3 (33.3%)\n",
      "        train: 3 (33.3%)\n",
      "        dev: 3 (33.3%)\n",
      "        total: 9\n",
      "    total this instance: 9\n",
      "    keys consistent: True\n",
      "    delegate:\n",
      "      name: sent_batch_stash\n",
      "      chunk_size: 0\n",
      "      workers: 2\n",
      "      batch_size: 4\n",
      "      data_point_id_sets_path: ../data/batch/b100/keys.dat\n",
      "      batch_limit: 3\n",
      "      delegate_attr: True\n",
      "      _has_data: True\n",
      "      is_child: False\n",
      "      _decoded_attributes: {'mask', 'tags', 'glove_50_embedding', 'ents', 'syns'}\n",
      "      priming: False\n",
      "  network settings:\n",
      "    name: net_settings\n",
      "    recurrent_crf_settings:\n",
      "      name: recurrent_crf_settings\n",
      "      dropout: 0.1\n",
      "      network_type: lstm\n",
      "      bidirectional: True\n",
      "      hidden_size: 24\n",
      "      num_layers: 1\n",
      "      num_labels: 9\n",
      "      decoder_settings:\n",
      "        name: linear_settings\n",
      "        middle_features:\n",
      "        proportions: True\n",
      "        repeats: 1\n",
      "      score_reduction: sum\n",
      "    mask_attribute: mask\n",
      "    tensor_predictions: False\n",
      "  model settings:\n",
      "    name: model_settings\n",
      "    path: ../target/model/glove_50_embedding\n",
      "    learning_rate: 0.001\n",
      "    epochs: 70\n",
      "    max_consecutive_increased_count: 9223372036854775807\n",
      "    nominal_labels: True\n",
      "    scheduler_class_name: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "    reduce_outcomes: none\n",
      "    shuffle_training: False\n",
      "    batch_limit: 9223372036854775807\n",
      "    batch_iteration: gpu\n",
      "    prediction_mapper_name: feature_prediction_mapper\n",
      "    cache_batches: True\n",
      "    gc_level: 0\n",
      "    batch_iteration_class_name: zensols.deeplearn.model.ScoredBatchIterator\n",
      "    criterion_class_name: torch.nn.CrossEntropyLoss\n",
      "    optimizer_class_name: torch.optim.Adam\n",
      "  model:\n",
      "    EmbeddedRecurrentCRF(\n",
      "      (embedding): WordVectorEmbeddingLayer(\n",
      "        (emb): Embedding(400001, 50)\n",
      "      )\n",
      "      (recurcrf): RecurrentCRF(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (recur): RecurrentAggregation(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (rnn): LSTM(116, 12, batch_first=True, bidirectional=True)\n",
      "        )\n",
      "        (decoder): DeepLinear(\n",
      "          (lin_layers): Sequential(\n",
      "            (0): Linear(in_features=24, out_features=9, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (crf): CRF(num_tags=9)\n",
      "      )\n",
      "    )\n",
      "    metadata:\n",
      "  data point: <class 'ner.domain.NERDataPoint'>\n",
      "  batch: <class 'ner.domain.NERBatch'>\n",
      "  mapping:\n",
      "    label: ents\n",
      "      label_vectorizer_manager\n",
      "        FieldFeatureMapping(attr='ents', feature_id='entlabel', is_agg=True, attr_access=None, is_label=True)\n",
      "        FieldFeatureMapping(attr='mask', feature_id='mask', is_agg=True, attr_access='ents', is_label=False)\n",
      "      language_feature_manager\n",
      "        FieldFeatureMapping(attr='tags', feature_id='tag', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='syns', feature_id='syn', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='glove_50_embedding', feature_id='wvglove50', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='glove_300_embedding', feature_id='wvglove300', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='word2vec_300_embedding', feature_id='w2v300', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='transformer_fixed_embedding', feature_id='transformer_fixed', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='transformer_trainable_embedding', feature_id='transformer_trainable', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='ents_trans', feature_id='entlabel_trans', is_agg=True, attr_access='trans_doc', is_label=True)\n",
      "        FieldFeatureMapping(attr='tags_expander', feature_id='transformer_tags_expander', is_agg=True, attr_access='doc', is_label=False)\n",
      "        FieldFeatureMapping(attr='syns_expander', feature_id='transformer_syns_expander', is_agg=True, attr_access='doc', is_label=False)\n",
      "  attributes:\n",
      "    ents\n",
      "      field:\n",
      "        FieldFeatureMapping(attr='ents', feature_id='entlabel', is_agg=True, attr_access=None, is_label=True)\n",
      "      vectorizer:\n",
      "        entlabel (aggregate vectorizer), shape: (-1, 1)\n",
      "    mask\n",
      "      field:\n",
      "        FieldFeatureMapping(attr='mask', feature_id='mask', is_agg=True, attr_access='ents', is_label=False)\n",
      "      vectorizer:\n",
      "        mask (mask), shape: (-1, 100)\n",
      "    tags\n",
      "      field:\n",
      "        FieldFeatureMapping(attr='tags', feature_id='tag', is_agg=True, attr_access='doc', is_label=False)\n",
      "      vectorizer:\n",
      "        tag (encoded feature document vectorizer), shape: (-1, -1, 45), feature type: TOKEN \n",
      "    syns\n",
      "      field:\n",
      "        FieldFeatureMapping(attr='syns', feature_id='syn', is_agg=True, attr_access='doc', is_label=False)\n",
      "      vectorizer:\n",
      "        syn (encoded feature document vectorizer), shape: (-1, -1, 21), feature type: TOKEN \n",
      "    glove_50_embedding\n",
      "      field:\n",
      "        FieldFeatureMapping(attr='glove_50_embedding', feature_id='wvglove50', is_agg=True, attr_access='doc', is_label=False)\n",
      "      vectorizer:\n",
      "        wvglove50 (word vector document embedding), shape: (-1, 50), feature type: EMBEDDING \n"
     ]
    }
   ],
   "source": [
    "from zensols.config import Writable\n",
    "# set indention level for human readable (pretty print) output\n",
    "Writable.WRITABLE_INDENT_SPACE = 2\n",
    "facade = mng.create_facade('glove50')\n",
    "facade.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model\n",
    "\n",
    "Train and test the model with the default (low) number of epochs to make sure everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-17 14:42:29,943 [zensols.deeplearn.model.executor.status] resetting executor\n",
      "2021-06-17 14:42:29,955 [zensols.deeplearn.model.facade] training...\n",
      "2021-06-17 14:42:29,964 [zensols.deeplearn.model.executor.status] batch iteration: gpu, limit: 9223372036854775807, caching: True, cached: 0\n",
      "2021-06-17 14:42:29,964 [zensols.deeplearn.model.executor.status] preparing datasets using iteration: gpu\n",
      "2021-06-17 14:42:29,965 [zensols.deeplearn.model.executor.status] using batch limit: 9223372036854775807 for train\n",
      "2021-06-17 14:42:29,982 [zensols.deeplearn.model.executor.status] using batch limit: 9223372036854775807 for dev\n",
      "2021-06-17 14:42:29,995 [zensols.deeplearn.model.executor.status] loaded 6 batches in 0s\n",
      "2021-06-17 14:42:29,995 [zensols.deeplearn.model.executor.status] train/test sets: 3 3\n",
      "2021-06-17 14:42:30,001 [zensols.deeplearn.model.executor.status] created model on cpu with use cuda: True, device: cuda:0\n",
      "2021-06-17 14:42:30,031 [zensols.deeplearn.model.executor.status] training model <class 'zensols.deepnlp.layer.embrecurcrf.EmbeddedRecurrentCRF'> on cuda:0 for 2 epochs using learning rate 0.001\n",
      "  0%|                                                                                             | 0/2 [00:00<?, ?it/s]2021-06-17 14:42:30,074 [zensols.deeplearn.model.executor.status] executed train in 0s\n",
      "2021-06-17 14:42:30,075 [zensols.deeplearn.model.executor.status] deallocating 6 batches\n",
      "2021-06-17 14:42:30,077 [zensols.deeplearn.model.facade] trained in 0s\n"
     ]
    },
    {
     "ename": "LayerError",
     "evalue": "The first two dimensions of emissions and tags must match, got (4, 15) and (4, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLayerError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ce1a32517e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfacade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/cli/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, display_results)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \"\"\"\n\u001b[1;32m    441\u001b[0m         \u001b[0mfacade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfacade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mfacade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mfacade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/facade.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, description)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/executor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, description)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dataset_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/executor.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, sets_name, description, func, ds_src)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'executed {sets_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mds_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                 \u001b[0mres_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{self.model_result.index}: {description}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/executor.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train, valid)\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'training on batch: {batch.id}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                     self.batch_iterator.iterate(\n\u001b[0m\u001b[1;32m    577\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                         train_epoch_result, DatasetSplitType.train)\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/batchiter.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, model, optimizer, criterion, batch, epoch_result, split_type)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             loss, labels, output = self._execute(\n\u001b[0m\u001b[1;32m    162\u001b[0m                 model, optimizer, criterion, batch, labels, split_type)\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/batchiter.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, model, optimizer, criterion, batch, labels, split_type)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mcctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScoredNetworkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mScoredNetworkOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/lib/python-3.9.4.opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'input batch: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/view/nlp/deepnlp/src/python/zensols/deepnlp/layer/embrecurcrf.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, batch, context)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 f'Attempting to use split {split_type} while training')\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDatasetSplitType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDatasetSplitType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/nlp/deepnlp/src/python/zensols/deepnlp/layer/embrecurcrf.py\u001b[0m in \u001b[0;36m_forward_train\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'super emb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recur'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/model/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'input batch: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/layer/recurcrf.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, mask, labels)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# entropy loss functions `ignore_index`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'training loss: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/lib/python-3.9.4.opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/layer/crf.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mreduction\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \"\"\"\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLayerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Invalid reduction: {reduction}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/view/ml/deeplearn/src/python/zensols/deeplearn/layer/crf.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, emissions, tags, mask)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0memissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 raise LayerError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;34m'The first two dimensions of emissions and tags must match, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     f'got {tuple(emissions.shape[:2])} and {tuple(tags.shape)}')\n",
      "\u001b[0;31mLayerError\u001b[0m: The first two dimensions of emissions and tags must match, got (4, 15) and (4, 100)"
     ]
    }
   ],
   "source": [
    "facade.epochs = 2\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters\n",
    "\n",
    "Set model parameters to get a feel for where they need to be before changing features.  Start with Glove 50 dimensional word embeddings with a learning rate of 0.01 and 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.learning_rate = 0.01\n",
    "facade.epochs = 20\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove 300 embeddings\n",
    "\n",
    "Next we use the same learning rate, but switch to the 300 dimension version of the embeddings.  The number of epochs is reduced because I have run the test before I know at what epoch the validation loss converges.  Since the model is saved only when the validation loss decreases, we early stop at 8 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.epochs = 8\n",
    "facade.embedding = 'glove_300_embedding'\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec Embeddings\n",
    "\n",
    "Now we switch to the Google 300D word2vec pretrained vectors using 12 epochs, even though it has converged at 9 epochs previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.epochs = 12\n",
    "facade.embedding = 'word2vec_300_embedding'\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Embeddings\n",
    "\n",
    "Now we test with Bert context aware frozen (not trainable) embeddings using 10 epochs.  We must empty the `net_settings` attributes, which are the lingustic features, since Bert tokenizes using the word piece algorithm and the tensor shapes will not align.  We'll address this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-fixed')\n",
    "facade.epochs = 10\n",
    "facade.net_settings.add_attributes = ()\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.net_settings.add_attributes = ('syns_expander', 'tags_expander')\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "facade = mng.create_facade('transformer-trainable')\n",
    "mng.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
