# language resource, which loads the SpacCy model and token normalizers
[filter_token_mapper]
remove_space = True

[map_filter_token_normalizer]
embed_entities = False

# creates features from documents by invoking by using SpaCy to parse the text
[doc_parser]
# remove empty sentences or sentences with only whitespace, which happens with
# two space separated sentences starting with spaCey 3
remove_empty_sentences = True
# indicate which features to keep after the parsing; if this is not given, all
# features are kept and persisted
#
# 'norm' is good for debuging, 'dep', 'children' and the rest are needed for
# dep head tree features
token_feature_ids = eval: set('norm sent_i tag tag_ dep_ idx'.split())


# lang features
[tag_replace_vectorizer]
class_name = zensols.deepnlp.vectorize.OneHotEncodedFeatureDocumentVectorizer
feature_id = tag
encode_transformed = False
optimize_bools = True
categories = eval: (${category_settings:tag})
feature_attribute = tag_

[syn_replace_vectorizer]
class_name = zensols.deepnlp.vectorize.OneHotEncodedFeatureDocumentVectorizer
feature_id = syn
encode_transformed = False
optimize_bools = True
categories = eval: (${category_settings:syn})
feature_attribute = syn_

[language_feature_manager]
configured_vectorizers = list:
  glove_50_feature_vectorizer,
  glove_300_feature_vectorizer,
  word2vec_300_feature_vectorizer,
  fasttext_news_300_feature_vectorizer,
  fasttext_crawl_300_feature_vectorizer,
  transformer_trainable_feature_vectorizer,
  transformer_fixed_feature_vectorizer,
  tag_replace_vectorizer,
  syn_replace_vectorizer